---
title: 'Class 09: Mini Project'
author: "Ethan Harding (PID A15468670)"
date: "10/26/2021"
output:
  pdf_document: default
  html_document: default
---

## 1. Exploratory Data Analysis

```{r}
# Place csv file into project directory, then assign it a variable name
fna.data <- "WisconsinCancer.csv"
# read.csv the csv file then assign it a name
wisc.df <- read.csv(fna.data, row.names=1)
head(wisc.df)
```

The first column contains the pathologist's diagnosis of if the cells are malignant or benign, we want to remove it from our data set. 
```{r}
wisc.data <- wisc.df[,-1]
head(wisc.data)
```

We still want to view the diagnosis column later to check, so we will save it as a  vector. 
```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
```

> **Q1.** How many observations are in this dataset?

```{r}
dim(wisc.data)
```

There are 569 observations in the "WisconsinCancer.csv" data set. 

> **Q2.** How many of the observations have a malignant diagnosis?

Use grep to find how many "M" there are in our diagnosis vector OR use table of diagnosis. 
```{r}
length(grep(pattern="M", x=diagnosis))
table(diagnosis)
```

There are 212 malignant diagnosis obersvations. 

> **Q3.** How many variables/features in the data are suffixed with _mean?

Use grep to find how many columns end in "_mean".
```{r}
length(grep("_mean", colnames(wisc.df)))
```
There are 10 variables / features in the data that are suffixed with "_mean". 

## 2. Principal Component Analysis

```{r}
# Check column means and their standard deviations
colMeans(wisc.data)
apply(wisc.data, 2, sd)
```

```{r}
# Perform PCA on wisc.data, we need to set the scale argument to true in order to scale the data. 
wisc.pr <- prcomp(wisc.data, scale.=TRUE)
# Look at the summary of the PCA results
summary(wisc.pr)
```

> **Q4.** From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44.27% of the original variance is captured by PC1. 

> **Q5.** How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3 principal components are required to describe at least 70% of the original variance in the data. 

> **Q6.** How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7 principal components are required to descibe at least 90& of the original variance in the data. 

Create a biplot of "wisc.pr"
```{r}
biplot(wisc.pr)
```
> **Q7.** What stands out to you about this plot? Is it easy or difficult to understand? Why?

This plot is very difficult to understand, it is just a giant blob of all the data set numbers and the column names. 

We are after the score plot(aka "PCA plot", PC1 vs PC2)

Let's generate a more standard scatter plot to make better sense of the observations along PC1 and PC2. 
```{r}
#Scatter plot observations by PC1 and PC2
plot(wisc.pr$x[,1:2], col=diagnosis, xlab="PC1", ylab="PC2")
```

> **Q8.** Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[, c(1,3)], col = diagnosis, xlab = "PC1", ylab = "PC3")
```

PC1 and PC2 are more clearly separated compared to PC1 and PC3. This is because PC2 describes more variance in the data than PC3. 

Now, let's use ggplot to to make fancier figures. 
```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + aes(PC1, PC2, col=diagnosis) + geom_point()

```


Calculate the variance of each principal component by squaring the sdev component of wisc.pr

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

Calculate the variance explained by each principal component by dividing by the total variance explained of all principal components

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Make an alternative scree plot of the same data
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
## ggplot based graph
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

> **Q9.** For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation[,1]
```

```{r}
wisc.pr$rotation["concave.points_mean",1]
```

> **Q10.** What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
summary(wisc.pr)
```

5 PC's are required to explain 80% of the variance of the data. 

## 3. Hierarchical Clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

Calculate the (Euclidean) distances between all pairs of observations in the new scaled dataset and assign the result to data.dist.
```{r}
data.dist <- dist(data.scaled)
```

Create a hierarchical clustering model using complete linkage. Manually specify the method argument to hclust() and assign the results to wisc.hclust.
```{r}
wisc.hclust <- hclust(data.dist, method = "complete")
```

> **Q11.** Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```
Height 19 is when the clustering model has 4 clusters. 

Use "cutree()" function to assign 4 clusters to wisc.hclust, then use "table()" to compare our cutree() cluster with the diagnosis. 
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
```


> **Q12.** Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

`No, it looks like 4 clusters seem to be the best amount to separate the different diagnoses. 

> **Q13.** Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

```{r}
plot(hclust(data.dist, method = "ward.D2"))
plot(hclust(data.dist, method = "single"))    
```

I prefer the "ward.D2" method as it gives the cleanest clustering model. 

## 5. Combining Methods

We take the results of our PCA analysis and cluster in this space 'wisc.pr$x'

```{r}
wisc.pr.hclust <- hclust(dist (wisc.pr$x[,1:3]), method = "ward.D2")
plot(wisc.pr.hclust)
abline(h=55, col="red", lty=2)
```

Cut the tree into k=2 groups
```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

> **Q15.** How well does the newly created model with four clusters separate out the two diagnoses?

Check to see if the 2 groups correspond to Benign and Malignant by doing a cross table.
```{r}
table(diagnosis, grps)
```

>**Q16.** How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.hclust.clusters, diagnosis)
# We skipped the kmeans section so we only have 1 option
```


## 6. Sensitivity and Specificity 

> **Q17.** Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

**Accuracy** What proportion did we get correct if we call cluster 1 M and cluster 2 B?
```{r}
(333+179)/nrow(wisc.data)
```

Now Calculate the Sensitivity and Specificity
```{r}
#Sensitivity <- TP/(TP + FP)
179/(179+33)
#Specificity <- TN/(TN + FN)
333/(333+24)
```


## 7. Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```


```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```
> **Q18.** Which of these new patients should we prioritize for follow up based on your results?

We should prioritize patient 2 for follow up because the red signifies patient 2 has malignant cancer cells, where as patient 1 is diagnosed with benign cells. 
